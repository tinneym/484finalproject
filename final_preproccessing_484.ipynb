{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWjai4J5kZlP"
      },
      "outputs": [],
      "source": [
        "# (1) EXTRACT DATASETS\n",
        "# Mount Colab account to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3QgXpxml-uv"
      },
      "outputs": [],
      "source": [
        "# Inspect dataset\n",
        "%cd /content/\n",
        "!pip install datasets\n",
        "from datasets import load_dataset, inspect_dataset\n",
        "inspect_dataset(\"ahazeemi/iwslt14-en-fr\", \"iwslt14\")  # replace with the datasets you are using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFHzIwOJPID7"
      },
      "outputs": [],
      "source": [
        "# Load dataset and generate train-test-validation splits\n",
        "# IWSLT '14 and WMT '14 data are stored in parquet files\n",
        "# IWSLT '17 data is already pre-split\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Example of loading IWSLT '14 FR-EN\n",
        "dataset = load_dataset('/content/iwslt14', data_files={'train': '/content/iwslt14/data/train-00000-of-00001.parquet', 'test': '/content/iwslt14/data/test-00000-of-00001.parquet', 'validation':'/content/iwslt14/data/validation-00000-of-00001.parquet'})\n",
        "\n",
        "# Example of loading WMT'14 FR-EN\n",
        "%cd /content/wmt14/de-en/\n",
        "\n",
        "directory = ''\n",
        "pattern = 'train-00000-of-0000*.parquet'  # Specify your wildcard pattern here\n",
        "\n",
        "train_files = glob.glob(os.path.join('', pattern))\n",
        "train_files.sort()\n",
        "\n",
        "print(train_files)\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "train_dataset = load_dataset('wmt14/de-en/', data_files=train_files)\n",
        "test_eval_dataset = load_dataset('wmt14/de-en/', data_files={'test': 'test-*.parquet', 'validation':'validation-*.parquet'})\n",
        "\n",
        "# Example of loading IWSLT '17 FR-EN\n",
        "dataset = load_dataset('/content/iwslt2017/iwslt2017.py', name='iwslt2017-fr-en')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets and then apply the IWSLT '14 splits for that language pair\n",
        "# Only need to change splits for IWSLT '17 and WMT '14\n",
        "from datasets import concatenate_datasets\n",
        "\n",
        "# For IWSLT '14\n",
        "train_data = dataset['train']['translation']\n",
        "eval_data = dataset['validation']['translation']\n",
        "test_data = dataset['test']['translation']\n",
        "\n",
        "# For WMT '14\n",
        "concatenated_dataset = concatenate_datasets([train_dataset['train'], test_eval_dataset['test'], test_eval_dataset['validation']])\n",
        "\n",
        "# For IWSLT '17\n",
        "concatenated_dataset = concatenate_datasets([dataset['train'], dataset['validation'], dataset['test']])\n",
        "\n",
        "# Generate new splits (only run this for IWSLT '17 and WMT '14)\n",
        "# Split sizes for IWSLT '14 (change hardcoded values depending on language pair)\n",
        "train_len = 179435\n",
        "test_len = 3666\n",
        "valid_len = 903\n",
        "\n",
        "# Calculate the slicing indices based on the lengths\n",
        "data = concatenated_dataset['translation']\n",
        "\n",
        "train_data = data[:train_len]\n",
        "eval_data = data[train_len:(train_len + valid_len)]\n",
        "test_data = data[(train_len + valid_len):(train_len + valid_len + test_len)]"
      ],
      "metadata": {
        "id": "qVKfcwazWElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if length of each split matches with IWSLT '14\n",
        "print(len(train_data))\n",
        "print(len(eval_data))\n",
        "print(len(test_data))\n",
        "\n",
        "# Check data\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "AYTJw2gsZu0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output splits into the right format in local folder\n",
        "def writeToTxt(data, key, output_file_path, count):\n",
        "   #key = lang i.e. 'de'\n",
        "    with open(output_file_path, mode='w') as file:\n",
        "        for row in data[:count]:\n",
        "          file.write(row[key] + '\\n')\n",
        "\n",
        "goalDir = '/content/res/'\n",
        "src = 'fr'  # change this depending on language\n",
        "\n",
        "# Change hardcoded numbers to the size of the splits\n",
        "writeToTxt(training_data, src, goalDir + 'train.' + src, 179435)\n",
        "writeToTxt(training_data, 'en', goalDir + 'train.en', 179435)\n",
        "writeToTxt(validation_data, src, goalDir + 'dev.'+src, 903)\n",
        "writeToTxt(validation_data, 'en', goalDir + 'dev.en', 903)\n",
        "writeToTxt(testing_data, src, goalDir + 'test.'+src, 3666)\n",
        "writeToTxt(testing_data, 'en', goalDir + 'test.en', 3666)"
      ],
      "metadata": {
        "id": "b9cW3r7JZy1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of lines in the txt files\n",
        "def printLines(filePath):\n",
        "  with open(filePath, 'r') as f:\n",
        "      lines = len(f.readlines())\n",
        "      print(lines)\n",
        "\n",
        "%cd /content/res/\n",
        "printLines(\"test.fr\")\n",
        "printLines(\"test.en\")\n",
        "printLines(\"train.fr\")\n",
        "printLines(\"train.en\")\n",
        "printLines(\"dev.fr\")\n",
        "printLines(\"dev.en\")"
      ],
      "metadata": {
        "id": "vS-miDAqBHqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save content in local folder to Google Drive\n",
        "!cp -r /content/res/ /content/gdrive/MyDrive/NLP-MLS/Datasets/iwslt14-fr-en # change destination"
      ],
      "metadata": {
        "id": "KlGzaUGeJtwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4SbEnFER7-0"
      },
      "outputs": [],
      "source": [
        "# Check content of files in Google Drive\n",
        "import os\n",
        "os.chdir(goalDir)\n",
        "!tail -5 test.fr\n",
        "!tail -5 test.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE-eJyY_5O_h"
      },
      "outputs": [],
      "source": [
        "# (2) PREPROCESS DATASETS\n",
        "# Set up environment\n",
        "import numpy\n",
        "if numpy.__version__ >= '1.24':\n",
        "  !pip uninstall -y numpy\n",
        "  !pip install \"numpy<1.24\"\n",
        "\n",
        "def install_torch():\n",
        "  !pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "install_torch()\n",
        "\n",
        "import torch\n",
        "try:\n",
        "    if torch.__version__ != '1.12.0+cu113':\n",
        "        !pip uninstall -y torch torchdata torchtext #make sure have correct torch version\n",
        "        install_torch()\n",
        "except ImportError:\n",
        "    install_torch()\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "!nvidia-smi\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-ubuntu1604.pin\n",
        "!mv cuda-ubuntu1604.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/11.3.0/local_installers/cuda-repo-ubuntu1604-11-3-local_11.3.0-465.19.01-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-11-3-local_11.3.0-465.19.01-1_amd64.deb\n",
        "\n",
        "!apt-key add /var/cuda-repo-ubuntu1604-11-3-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get -y install cuda-11-3\n",
        "!apt autoremove\n",
        "\n",
        "!nvcc --version\n",
        "\n",
        "!update-alternatives --set cuda /usr/local/cuda-11.3\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "!nvcc --version\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVnbbBETk30l"
      },
      "outputs": [],
      "source": [
        "# Clone paper's Github repo and install requirements\n",
        "! apt-get install git\n",
        "\n",
        "!ssh-keygen -t rsa -b 4096\n",
        "!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "!cat /root/.ssh/id_rsa.pub  # add SSH key to your Github\n",
        "\n",
        "%cd /content/\n",
        "!git clone git@github.com:chenllliang/MLS.git\n",
        "\n",
        "%cd /content/MLS/fairseq\n",
        "!pip install --editable ./\n",
        "!pip install sacremoses\n",
        "\n",
        "%cd /content/\n",
        "!git clone git@github.com:moses-smt/mosesdecoder.git /content/MLS/Tools/mosesdecoder/\n",
        "!git clone git@github.com:rsennrich/subword-nmt.git /content/MLS/Tools/subword-nmt/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ7z0wEN2Krf"
      },
      "outputs": [],
      "source": [
        "# Code to unzip databin file\n",
        "!unzip /content/MLS/databin/iwslt14-de-en-bin.zip -d /content/MLS/databin/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to remove databin contents\n",
        "!rm -r /content/MLS/databin/iwslt14-de-en-isolated-new/\n",
        "!rm -r /content/MLS/databin/iwslt14-de-en-joined-new"
      ],
      "metadata": {
        "id": "IHKB3AY8Uhct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ4HyXle4UAq"
      },
      "outputs": [],
      "source": [
        "# Run preprocessing script\n",
        "%cd /content/MLS/scripts/\n",
        "!bash preprocess.sh /content/gdrive/MyDrive/NLP-MLS/Datasets/iwslt14-fr-en-/res/ en fr  # change destination and languages\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save files from runtime to Google Drive (change destination)\n",
        "!cp -r /content/res/ /content/gdrive/MyDrive/NLP-MLS/Datasets/iwslt14-fr/res/\n",
        "!cp -r /content/MLS/databin/iwslt14-de-en-isolated-new/ /content/gdrive/MyDrive/NLP-MLS/Datasets/iwslt14-fr-en/iwslt14-fr-en-isolated-new/\n",
        "!cp -r /content/MLS/databin/iwslt14-de-en-joined-new/ /content/gdrive/MyDrive/NLP-MLS/Datasets/iwslt14-fr-en/iwslt14-fr-en-joined-new/"
      ],
      "metadata": {
        "id": "IpBQAdkwOC5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}